{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19be98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a53e7",
   "metadata": {},
   "source": [
    "# Download utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
    "# !tar -xjf LJSpeech-1.1.tar.bz2\n",
    "# !mv LJSpeech-1.1/ hw_tts/data/\n",
    "# !mv LJSpeech-1.1.tar.bz2 hw_tts/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1764e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install librosa\n",
    "# %pip3 install googledrivedownloader\n",
    "# %pip3 install torch==1.10.0+cu111 torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/NVIDIA/waveglow.git\n",
    "# !mv waveglow/ hw_tts/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd3f5a",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c969b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ef5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from hw_tts.datasets import LJSpeechDataset, collate_fn\n",
    "from hw_tts.melspecs import MelSpectrogram, MelSpectrogramConfig\n",
    "\n",
    "featurizer = MelSpectrogram(MelSpectrogramConfig())\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = DataLoader(LJSpeechDataset('./hw_tts/data/'), batch_size=4, collate_fn=collate_fn)\n",
    "\n",
    "test_batch = next(iter(dataloader))\n",
    "test_batch[\"melspecs\"] = featurizer(test_batch[\"waveforms\"]).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21878faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw_tts.aligners import GraphemeAligner\n",
    "\n",
    "aligner = GraphemeAligner(melspec_sr=22050).to(DEVICE)\n",
    "\n",
    "test_batch[\"durations\"] = (aligner(\n",
    "    test_batch[\"waveforms\"].to(DEVICE), test_batch[\"waveforms_lengths\"], test_batch[\"transcripts\"]\n",
    ") * test_batch[\"melspecs\"].shape[-2]).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a77254",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3659e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 769, 80]), torch.Size([4, 833, 80]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hw_tts.models import FastSpeech\n",
    "\n",
    "model = FastSpeech(\n",
    "    d_model=384,\n",
    "    n_head=2,\n",
    "    n_tokens=51,\n",
    "    n_encoders=6,\n",
    "    n_decoders=6,\n",
    "    hidden_size=1536,\n",
    "    duration_hidden=256,\n",
    "    alpha=1.,\n",
    "    melspec_size=80,\n",
    "    kernel_size=3\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "l2 = nn.MSELoss()\n",
    "l1 = nn.L1Loss()\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "n_iters = 1\n",
    "for _ in range(n_iters):\n",
    "    mels, durs = model(test_batch)\n",
    "    max_mel_len = min(mels.shape[-2], test_batch[\"melspecs\"].shape[-2])\n",
    "    \n",
    "    loss = l2(mels[:, :max_mel_len], test_batch[\"melspecs\"][:, :max_mel_len]) + \\\n",
    "        l1(durs, test_batch[\"durations\"].float())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.plot(loss_values)\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2bfa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+------------+\n",
      "|                                   Modules                                    | Parameters |\n",
      "+------------------------------------------------------------------------------+------------+\n",
      "|                               embedding.weight                               |   19584    |\n",
      "|                    encoder_layers.0.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.0.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.0.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.0.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.0.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.0.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.0.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.0.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.0.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.0.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.0.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.0.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.0.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.0.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.0.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.0.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.0.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.0.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.0.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.0.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.0.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.0.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.0.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.0.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.0.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.0.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.0.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.0.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.0.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.0.convs.layers.2.bias                     |    384     |\n",
      "|                    encoder_layers.1.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.1.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.1.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.1.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.1.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.1.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.1.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.1.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.1.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.1.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.1.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.1.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.1.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.1.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.1.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.1.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.1.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.1.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.1.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.1.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.1.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.1.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.1.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.1.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.1.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.1.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.1.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.1.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.1.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.1.convs.layers.2.bias                     |    384     |\n",
      "|                    encoder_layers.2.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.2.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.2.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.2.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.2.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.2.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.2.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.2.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.2.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.2.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.2.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.2.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.2.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.2.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.2.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.2.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.2.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.2.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.2.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.2.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.2.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.2.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.2.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.2.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.2.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.2.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.2.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.2.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.2.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.2.convs.layers.2.bias                     |    384     |\n",
      "|                    encoder_layers.3.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.3.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.3.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.3.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.3.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.3.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.3.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.3.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.3.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.3.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.3.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.3.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.3.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.3.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.3.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.3.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.3.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.3.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.3.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.3.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.3.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.3.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.3.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.3.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.3.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.3.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.3.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.3.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.3.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.3.convs.layers.2.bias                     |    384     |\n",
      "|                    encoder_layers.4.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.4.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.4.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.4.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.4.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.4.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.4.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.4.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.4.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.4.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.4.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.4.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.4.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.4.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.4.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.4.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.4.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.4.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.4.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.4.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.4.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.4.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.4.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.4.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.4.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.4.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.4.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.4.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.4.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.4.convs.layers.2.bias                     |    384     |\n",
      "|                    encoder_layers.5.multihead.norm.weight                    |    384     |\n",
      "|                     encoder_layers.5.multihead.norm.bias                     |    384     |\n",
      "|           encoder_layers.5.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            encoder_layers.5.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            encoder_layers.5.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             encoder_layers.5.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           encoder_layers.5.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            encoder_layers.5.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| encoder_layers.5.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.5.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.5.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.5.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.5.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.5.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| encoder_layers.5.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  encoder_layers.5.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  encoder_layers.5.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   encoder_layers.5.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| encoder_layers.5.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  encoder_layers.5.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                encoder_layers.5.multihead.output_layer.weight                |   147456   |\n",
      "|                 encoder_layers.5.multihead.output_layer.bias                 |    384     |\n",
      "|                        encoder_layers.5.norm1.weight                         |    384     |\n",
      "|                         encoder_layers.5.norm1.bias                          |    384     |\n",
      "|                        encoder_layers.5.norm2.weight                         |    384     |\n",
      "|                         encoder_layers.5.norm2.bias                          |    384     |\n",
      "|                    encoder_layers.5.convs.layers.0.weight                    |  1769472   |\n",
      "|                     encoder_layers.5.convs.layers.0.bias                     |    1536    |\n",
      "|                    encoder_layers.5.convs.layers.2.weight                    |  1769472   |\n",
      "|                     encoder_layers.5.convs.layers.2.bias                     |    384     |\n",
      "|                      duration_predictor.conv1.0.weight                       |   294912   |\n",
      "|                       duration_predictor.conv1.0.bias                        |    256     |\n",
      "|                       duration_predictor.norm1.weight                        |    256     |\n",
      "|                        duration_predictor.norm1.bias                         |    256     |\n",
      "|                      duration_predictor.conv2.0.weight                       |   294912   |\n",
      "|                       duration_predictor.conv2.0.bias                        |    384     |\n",
      "|                       duration_predictor.norm2.weight                        |    384     |\n",
      "|                        duration_predictor.norm2.bias                         |    384     |\n",
      "|                     duration_predictor.regressor.weight                      |    384     |\n",
      "|                      duration_predictor.regressor.bias                       |     1      |\n",
      "|                    decoder_layers.0.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.0.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.0.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.0.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.0.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.0.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.0.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.0.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.0.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.0.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.0.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.0.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.0.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.0.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.0.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.0.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.0.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.0.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.0.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.0.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.0.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.0.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.0.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.0.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.0.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.0.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.0.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.0.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.0.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.0.convs.layers.2.bias                     |    384     |\n",
      "|                    decoder_layers.1.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.1.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.1.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.1.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.1.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.1.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.1.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.1.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.1.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.1.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.1.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.1.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.1.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.1.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.1.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.1.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.1.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.1.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.1.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.1.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.1.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.1.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.1.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.1.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.1.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.1.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.1.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.1.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.1.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.1.convs.layers.2.bias                     |    384     |\n",
      "|                    decoder_layers.2.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.2.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.2.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.2.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.2.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.2.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.2.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.2.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.2.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.2.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.2.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.2.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.2.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.2.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.2.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.2.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.2.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.2.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.2.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.2.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.2.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.2.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.2.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.2.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.2.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.2.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.2.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.2.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.2.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.2.convs.layers.2.bias                     |    384     |\n",
      "|                    decoder_layers.3.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.3.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.3.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.3.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.3.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.3.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.3.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.3.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.3.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.3.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.3.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.3.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.3.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.3.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.3.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.3.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.3.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.3.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.3.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.3.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.3.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.3.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.3.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.3.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.3.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.3.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.3.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.3.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.3.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.3.convs.layers.2.bias                     |    384     |\n",
      "|                    decoder_layers.4.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.4.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.4.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.4.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.4.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.4.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.4.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.4.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.4.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.4.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.4.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.4.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.4.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.4.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.4.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.4.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.4.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.4.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.4.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.4.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.4.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.4.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.4.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.4.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.4.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.4.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.4.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.4.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.4.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.4.convs.layers.2.bias                     |    384     |\n",
      "|                    decoder_layers.5.multihead.norm.weight                    |    384     |\n",
      "|                     decoder_layers.5.multihead.norm.bias                     |    384     |\n",
      "|           decoder_layers.5.multihead.initial_layers.query.0.weight           |   147456   |\n",
      "|            decoder_layers.5.multihead.initial_layers.query.0.bias            |    384     |\n",
      "|            decoder_layers.5.multihead.initial_layers.key.0.weight            |   147456   |\n",
      "|             decoder_layers.5.multihead.initial_layers.key.0.bias             |    384     |\n",
      "|           decoder_layers.5.multihead.initial_layers.value.0.weight           |   147456   |\n",
      "|            decoder_layers.5.multihead.initial_layers.value.0.bias            |    384     |\n",
      "| decoder_layers.5.multihead.attention_heads.0.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.5.multihead.attention_heads.0.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.5.multihead.attention_heads.0.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.5.multihead.attention_heads.0.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.5.multihead.attention_heads.0.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.5.multihead.attention_heads.0.initial_transforms.value.bias  |    192     |\n",
      "| decoder_layers.5.multihead.attention_heads.1.initial_transforms.query.weight |   73728    |\n",
      "|  decoder_layers.5.multihead.attention_heads.1.initial_transforms.query.bias  |    192     |\n",
      "|  decoder_layers.5.multihead.attention_heads.1.initial_transforms.key.weight  |   73728    |\n",
      "|   decoder_layers.5.multihead.attention_heads.1.initial_transforms.key.bias   |    192     |\n",
      "| decoder_layers.5.multihead.attention_heads.1.initial_transforms.value.weight |   73728    |\n",
      "|  decoder_layers.5.multihead.attention_heads.1.initial_transforms.value.bias  |    192     |\n",
      "|                decoder_layers.5.multihead.output_layer.weight                |   147456   |\n",
      "|                 decoder_layers.5.multihead.output_layer.bias                 |    384     |\n",
      "|                        decoder_layers.5.norm1.weight                         |    384     |\n",
      "|                         decoder_layers.5.norm1.bias                          |    384     |\n",
      "|                        decoder_layers.5.norm2.weight                         |    384     |\n",
      "|                         decoder_layers.5.norm2.bias                          |    384     |\n",
      "|                    decoder_layers.5.convs.layers.0.weight                    |  1769472   |\n",
      "|                     decoder_layers.5.convs.layers.0.bias                     |    1536    |\n",
      "|                    decoder_layers.5.convs.layers.2.weight                    |  1769472   |\n",
      "|                     decoder_layers.5.convs.layers.2.bias                     |    384     |\n",
      "|                           decoder_layers.6.weight                            |   30720    |\n",
      "|                            decoder_layers.6.bias                             |     80     |\n",
      "+------------------------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 55579089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55579089"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "model = FastSpeech(\n",
    "    d_model=384,\n",
    "    n_head=2,\n",
    "    n_tokens=51,\n",
    "    n_encoders=6,\n",
    "    n_decoders=6,\n",
    "    hidden_size=1536,\n",
    "    duration_hidden=256,\n",
    "    alpha=1.,\n",
    "    melspec_size=80,\n",
    "    kernel_size=3\n",
    ")\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae737ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
